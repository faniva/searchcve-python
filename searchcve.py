#!/usr/bin/env python3

# Stanislas M. 2021-09-28

"""
usage: searchcve_api.py [-h] [-c CVE] [-k KEYWORD] [-u URL] [-i INPUT_FILE]

optional arguments:
  -h, --help            show this help message and exit
  -c CVE, --cve CVE     Choose CVE e.g. "CVE-2020-1472"
  -k KEYWORD, --keyword KEYWORD
                        Choose keyword e.g. "microsoft" -- it will give the 20 latest vulnerabilities and export to csv in the current directory
  -u URL, --url URL     Choose URL e.g. "https://nvd.nist.gov/" -- it will export to csv in the current directory
  -i INPUT_FILE, --input-file INPUT_FILE
                        Choose the path to input file containing CVEs or URLs e.g. "test.csv" -- it will export to csv in the current directory
"""

import json
import argparse
import re
import requests
from bs4 import BeautifulSoup
from pathlib import Path
from datetime import datetime
from urllib.parse import quote, urlencode
import time
from prettytable import PrettyTable
import csv as csvw
import os
from dotenv import load_dotenv

load_dotenv()

# disable ssl warning in case of proxy like Zscaler which breaks ssl...
requests.packages.urllib3.disable_warnings()

# Your proxy here...
proxy = ""

# Base CVE API
nist_base_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
nist_api_key = os.environ.get('NVD_API_KEY')

# Current date
now = datetime.now()
today = now.strftime("%Y-%m-%d-%H_%M_%S")

# CHECKS

def is_cve(txt):
    match = re.search("(CVE|cve)-[0-9]{4}-[0-9]{4,}$", txt)
    if match:
        return True
    else:
        return False

def is_url(txt):
    if "http" in txt:
        return True
    else:
        return False

def find_urls(string):
    # Credit https://www.geeksforgeeks.org/python-check-url-string/
    # findall() has been used 
    # with valid conditions for urls in string
    regex = r"(?i)\b((?:https?://|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>]+|\(([^\s()<>]+|(\([^\s()<>]+\)))*\))+(?:\(([^\s()<>]+|(\([^\s()<>]+\)))*\)|[^\s`!()\[\]{};:'\".,<>?«»“”‘’]))"
    url = re.findall(regex,string)      
    return [x[0] for x in url]

def export_to_csv():
    filename = "{}-export.csv".format(today)
    print("\nGenerated CSV: ./{}-cve-export.csv\n".format(filename))
    f = open(filename, "a")
    f.write(csv)
    f.close()


# Core function

def searchcve(url):
    cvss_list = []
    cves_list = []
    sources_list = []
    url_list = []
    global csv

    # print('Searching cve url --- {}'.format(url))

    # Create a CSV writer object
    filename = "{}-export.csv".format(today)

    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
        csv_writer = csvw.writer(csvfile, quoting=csvw.QUOTE_MINIMAL)

        proxy_servers = { 'http': proxy, 'https': proxy }
        headers: dict = {}
        if nist_api_key:
            headers['apiKey'] = nist_api_key

        # print(headers)
        base_request = requests.get(url, timeout=10, proxies=proxy_servers, headers=headers, verify=True)
        base_request.raise_for_status()

        if base_request.status_code == 200:
            base_text = base_request.text
            cve_search = re.findall("CVE-[0-9]{4}-[0-9]{4,}", base_text)

            if cve_search == []:
                print("[i] No CVE found, aborting.")
                return

            # Get unique CVEs
            cves_list = sorted(set(cve_search))

            table = PrettyTable()
        
            if extra_columns:
                table.field_names = ["CVE", "CVSS", "Source", "URL"] + extra_columns
            else:
                table.field_names = ["CVE", "CVSS", "Source", "URL"]

            # Add csv header row
            csv_writer.writerow(table.field_names)
                 
            for i in range (0, len(cves_list)):
                # print(cves_list[i])
                cve = ""
                source = ""
                published_date = ""
                last_modified_date = ""
                description = ""
                cveinfo = None

                if i>0:
                    time.sleep(2) # sleep for 2 seconds
                        
                if is_cve(cves_list[i]):
                    cveinfo = query_cve_by_id(cves_list[i])
                    if cveinfo:
                        cve = cveinfo["vulnerabilities"][0]["cve"]["id"]
                        source = cveinfo["vulnerabilities"][0]["cve"]["sourceIdentifier"]
                        published_date = cveinfo["vulnerabilities"][0]["cve"]["published"]
                        last_modified_date = cveinfo["vulnerabilities"][0]["cve"]["lastModified"].split("T")[0]
                        description = cveinfo["vulnerabilities"][0]["cve"]["descriptions"][0]["value"]

                        if description.startswith("** REJECT **"):
                            # Skip this CVE if it's marked as 'REJECT'
                            continue

                        if datetime(2019, 1, 1) > datetime.fromisoformat(published_date):
                            # Skip this CVE if its published outside of the date range we want 
                            continue

                        description = (description.strip()[:100] + "..." if len(description) > 100 else description.strip() ) if description else ''
                        published_date = published_date.split("T")[0]
                        # print("CVE: {}".format(cve))
                        # print(cveinfo)
                        # print(description)      

                # URL
                nist_url = "https://nvd.nist.gov/vuln/detail/{}".format(cves_list[i])
                headers = {}
                # if nist_api_key:
                #     headers = {
                #         'apiKey': nist_api_key 
                #     }

                nist_request = requests.get(nist_url, timeout=10, proxies=proxy_servers, headers=headers, verify=False) 

                soup = BeautifulSoup(nist_request.text, "html.parser")

                # CVSS
                try:
                    el_parent = soup.find("input",attrs={ "id" : "nistV3MetricHidden" })["value"] 
                    soup_internal = BeautifulSoup(el_parent, "html.parser")
                    cvss = soup_internal.find_all(
                        "span", 
                        attrs={ 
                            "data-testid": "vuln-cvssv3-base-score" 
                        }
                )[0].string.strip() 
                except Exception: 
                    cvss = "0.0" 
                
                # Source
                try: 
                    source = soup.find_all(
                        "span", 
                        attrs={ 
                            "data-testid": "vuln-current-description-source" 
                        } 
                )[0].string.strip().replace(",", "") 
                except Exception: 
                    source = "Unknown"

                cvssf = float(cvss)
                cvss_list.append(cvssf)

                url_list.append(nist_url)

                sources_list.append(source)
                
                # CSV text
                # print(table.field_names)
                # print(type(table.field_names))
            
                # csv = ",".join(table.field_names) + "\n" # csv header row
                
                # print(csv)            

                # Handle extra column fields 
                extra_fields_dict = {
                    "Published Date": published_date,
                    "Last Modified": last_modified_date,
                    "Description": description
                }

                # csv += cves_list[i] + "," + cvss + "," + source + "," + nist_url + "\n"
                tablecols = [cves_list[i], cvss, source, nist_url]
                def map_extra_field_val(col):
                    return extra_fields_dict[col]
                
                tablecols += list(map(map_extra_field_val, extra_columns))
                # csv += ",".join(tablecols) + "\n"

                csv_writer.writerow(tablecols)
                
                table.add_row(tablecols)
            
                # Printing during the loop, erasing
                print("\033[2J\033[H" + str(table))

            # Max CVSS
            print("\n[i] Max CVSS: {}".format(str(max(cvss_list))))
            # The output file location
            print("\nLocation: {}".format(os.path.realpath(csvfile.name)))

            # Export
            # export_to_csv()
            csv = ""

        else:
            raise Exception("[!] HTTP error: {}".format(str(base_request.status_code))) 

# CVE -c / --cve

def action_cve(txt):
    if is_cve(txt):
        cve_info(txt)
    else:
        print('[!] "{}" is not a valid CVE, aborting.'.format(txt))


def query_cve_by_id(cve_id):
    proxy_servers = { 'http': proxy, 'https': proxy }
    nist_api_url = "{}?cveId={}".format(nist_base_url, cve_id)
    headers = {}
    if nist_api_key:
        headers = {
            'apiKey': nist_api_key
        }
    base_request = requests.get(nist_api_url, timeout=10, proxies=proxy_servers, headers=headers, verify=False)
    if base_request.status_code == 200:
        # return json.loads(base_request.text)
        return base_request.json()
    else:
        return False
        

def cve_info(txt):
    todos = query_cve_by_id(txt)
    if todos:
        cve = todos["vulnerabilities"][0]["cve"]["id"]
        source = todos["vulnerabilities"][0]["cve"]["sourceIdentifier"]
        published_date = todos["vulnerabilities"][0]["cve"]["published"].split("T")[0]
        last_modified_date = todos["vulnerabilities"][0]["cve"]["lastModified"].split("T")[0]
        english_description = todos["vulnerabilities"][0]["cve"]["descriptions"][0]["value"]
        print("CVE: {}".format(cve))
        print("Published date: {}".format(published_date))
        print("Last modified date: {}".format(last_modified_date))
        print("Source: {}".format(source))
        print("Description: {}".format(english_description))
        
        try:
            cvss = todos["vulnerabilities"][0]["cve"]["metrics"]["cvssMetricV31"][0]["cvssData"]["baseScore"]
            severity = todos["vulnerabilities"][0]["cve"]["metrics"]["cvssMetricV31"][0]["cvssData"]["baseSeverity"]
            print("CVSS 3.1 (Base Score): {} ({})".format(cvss, severity))

        except KeyError:
            print("CVSS 3.1 (Base Score): Unknown or too old")
            cvss = "0.0"
        nist_url = "https://nvd.nist.gov/vuln/detail/{}".format(txt)
        print("More info: {} \n".format(nist_url))

        if args.input_file:
            global csv
            csv += cve + "," + str(cvss) + "," + source + "," + nist_url + "\n"
            # Add delay to avoid blocking
            delay = 30
            print("[i] Waiting {} seconds to avoid API limitations...".format(delay))
            time.sleep(delay)
    else:
        print('[!] "{}" not found in database.'.format(txt))

# KEYWORD -k / --keyword

def action_keyword(txt):
    if txt != "":
        action_url("{}?keywordSearch={}".format(nist_base_url, txt))
    else:
        print('[!] "{}" is not a valid keyword, aborting.'.format(txt))

# URL -u / --url

def action_url(txt):
    if is_url(txt):
        print(txt)
        searchcve(txt)
    else:
        print('[!] "{}" is not a valid URL, aborting.'.format(txt))

# INPUT_FILE -i / --input-file

def action_file(txt):
    if Path(txt).is_file():
        input_file = open(txt, "r")
        data = input_file.read()
        input_file.close()
        cves_list_file = re.findall("CVE-[0-9]{4}-[0-9]{4,}", data, flags=re.IGNORECASE)
        urls_list_file = find_urls(data)
        if cves_list_file != []:
            sorted_cves_file = sorted(set(cves_list_file))
            for i in range (0, len(sorted_cves_file)):
                action_cve(sorted_cves_file[i])
            # Export
            export_to_csv()
        if urls_list_file != []:
            for i in range (0, len(urls_list_file)):
                action_url(urls_list_file[i])
    else:
        print('[!] "{}" is not a valid file, aborting.'.format(txt))


def parse_add_fields_arg(value):
    if value:
        return value.split(',')
    else:
        return []

# MAIN
def main(): 
    parser = argparse.ArgumentParser()
    parser.add_argument('-c','--cve', help='Choose CVE e.g. "CVE-2020-1472"')
    keyword_group = parser.add_argument_group(title='keyword options')
    keyword_group.add_argument('-k','--keyword', help='Choose keyword e.g. "microsoft" -- it will give the 12 latest vulnerabilities and export to csv in the current directory')
    keyword_group.add_argument('--add-fields',type=parse_add_fields_arg, metavar="COL1,COL2,..COLN", help='Add extra fields to the final CSV report. Only use with -k argument')
    parser.add_argument('-u','--url', help='Choose URL e.g. "https://nvd.nist.gov/" -- it will export to csv in the current directory')
    parser.add_argument('-i','--input-file', help='Choose the path to input file containing CVEs or URLs e.g. "test.csv" -- it will export to csv in the current directory')
    
    global args
    global extra_columns
    extra_columns = []

    args = parser.parse_args()

    # print(args)
    if args.add_fields and not args.keyword:
         parser.error("--add-fields can only be used in combination with --keyword") 

    if args.cve:
        action_cve(args.cve)

    if args.keyword:       
        extra_columns = args.add_fields
        action_keyword(args.keyword)

    if args.url:
        action_url(args.url)

    if args.input_file:
        action_file(args.input_file)    

if __name__ == "__main__":
    try: 
        main()
    except KeyboardInterrupt:
        print("\n[!] KeyboardInterrupt Detected.")
        print("[i] Exiting...")
        exit(0)
    except Exception as err: 
        print("[!] General error: {}".format(str(err)))
        exit(1)
    
